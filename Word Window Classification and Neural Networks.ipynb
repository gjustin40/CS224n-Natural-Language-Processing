{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Word Window Classification and Neural Networks\n",
    "- Implementation word window classification\n",
    "- https://nbviewer.jupyter.org/github/DSKSD/DeepNLP-models-Pytorch/blob/master/notebooks/04.Window-Classifier-for-NER.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import nltk\n",
    "import random\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "flatten = lambda l: [item for sublist in l for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn_crfsuite import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4.1\n",
      "3.2.4\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)\n",
    "print(nltk.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "gpus = [0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "cuda runtime error (35) : CUDA driver version is insufficient for CUDA runtime version at torch/csrc/cuda/Module.cpp:32",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-47c41edc6c7e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_device\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgpus\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\cuda\\__init__.py\u001b[0m in \u001b[0;36mset_device\u001b[1;34m(device)\u001b[0m\n\u001b[0;32m    260\u001b[0m     \"\"\"\n\u001b[0;32m    261\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mdevice\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 262\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_cuda_setDevice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    263\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: cuda runtime error (35) : CUDA driver version is insufficient for CUDA runtime version at torch/csrc/cuda/Module.cpp:32"
     ]
    }
   ],
   "source": [
    "torch.cuda.set_device(gpus[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "FloatTensor = torch.cuda.FloatTensor if use_cuda else torch.FloatTensor\n",
    "LongTensor = torch.cuda.LongTensor if use_cuda else torch.LongTensor\n",
    "ByteTensor = torch.cuda.ByteTensor if use_cuda else torch.ByteTensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Setting Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getBatch(batch_size, train_data):\n",
    "    random.shuffle(train_data)\n",
    "    sindex = 0\n",
    "    eindex = batch_size\n",
    "    while eindex < len(train_data):\n",
    "        batch = train_data[sindex: eindex]\n",
    "        temp = eindex\n",
    "        eindex = eindex + batch_size\n",
    "        sindex = temp\n",
    "        yield batch\n",
    "    \n",
    "    if eindex >= len(train_data):\n",
    "        batch = train_data[sindex:]\n",
    "        yield batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_sequence(seq, word2index):\n",
    "    idxs = list(map(lambda w: word2index[w] if word2index.get(w) is not None else word2index[\"<UNK>\"], seq))\n",
    "    return Variable(LongTensor(idxs))\n",
    "\n",
    "def prepare_word(word, word2index):\n",
    "    return Variable(LongTensor([word2index[word]]) if word2index.get(word) is not None else LongTensor([word2index[\"<UNK>\"]]))\n",
    "\n",
    "def prepare_tag(tag,tag2index):\n",
    "    return Variable(LongTensor([tag2index[tag]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data load and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('Sao', 'NC', 'B-LOC'), ('Paulo', 'VMI', 'I-LOC'), ('(', 'Fpa', 'O'), ('Brasil', 'NC', 'B-LOC'), (')', 'Fpt', 'O'), (',', 'Fc', 'O'), ('23', 'Z', 'O'), ('may', 'NC', 'O'), ('(', 'Fpa', 'O'), ('EFECOM', 'NP', 'B-ORG'), (')', 'Fpt', 'O'), ('.', 'Fp', 'O')], [('-', 'Fg', 'O')], ...]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = nltk.corpus.conll2002.iob_sents()\n",
    "corpus # 각 list안에는 한 문장이 들어가는데,\n",
    "       # 각 문장의 단어들이 (단어, chunck, tag)로 형성되어 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "for cor in corpus:\n",
    "    sent, _, tag = list(zip(*cor))  # zip(*iterable) 여기서 *는 묶는 방식을 바꾼다.\n",
    "                                    # 일반 zip : [(a1 b1), (a2, b2)], *추가 : [(a1,a2), (b1,b2)]\n",
    "                                    # '_'은 불러오기는 하지만 따로 변수에 저장하지는 않겠다는 뜻\n",
    "    data.append([sent, tag])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(('Sao', 'NC', 'B-LOC'),), (('Paulo', 'VMI', 'I-LOC'),), (('(', 'Fpa', 'O'),), (('Brasil', 'NC', 'B-LOC'),), ((')', 'Fpt', 'O'),), ((',', 'Fc', 'O'),), (('23', 'Z', 'O'),), (('may', 'NC', 'O'),), (('(', 'Fpa', 'O'),), (('EFECOM', 'NP', 'B-ORG'),), ((')', 'Fpt', 'O'),), (('.', 'Fp', 'O'),)]\n",
      "\n",
      "[('Sao', 'Paulo', '(', 'Brasil', ')', ',', '23', 'may', '(', 'EFECOM', ')', '.'), ('NC', 'VMI', 'Fpa', 'NC', 'Fpt', 'Fc', 'Z', 'NC', 'Fpa', 'NP', 'Fpt', 'Fp'), ('B-LOC', 'I-LOC', 'O', 'B-LOC', 'O', 'O', 'O', 'O', 'O', 'B-ORG', 'O', 'O')]\n"
     ]
    }
   ],
   "source": [
    "# what the cor looks like?\n",
    "print(list(zip(corpus[0]))) # [(단어1, chunck1, tag1), (단어2, chunck2, tag2), ....]\n",
    "print('')\n",
    "print(list(zip(*corpus[0]))) # [(단어1, 단어2 ....), (chunck1, chunck2, ....), (tag1, tag2, ...)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35651\n",
      "[('Sao', 'Paulo', '(', 'Brasil', ')', ',', '23', 'may', '(', 'EFECOM', ')', '.'), ('B-LOC', 'I-LOC', 'O', 'B-LOC', 'O', 'O', 'O', 'O', 'O', 'B-ORG', 'O', 'O')]\n"
     ]
    }
   ],
   "source": [
    "print(len(data))\n",
    "print(data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Build vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Sao', 'Paulo', '(', 'Brasil', ')', ',', '23', 'may', '(', 'EFECOM', ')', '.')\n",
      "\n",
      "O\n"
     ]
    }
   ],
   "source": [
    "sents, tags = list(zip(*data))\n",
    "print(sents[0])\n",
    "print('')\n",
    "print(tag[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = list(set(flatten(sents))) # 단어 list를 만들고 set를 통해 중복되는 단어 제거\n",
    "tagset = list(set(flatten(tags))) # 위와 같음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2index = {'<UNK>' : 0, '<DUMMY>' : 1}\n",
    "for vo in vocab:\n",
    "    if word2index.get(vo) is None:\n",
    "        word2index[vo] = len(word2index)\n",
    "index2word = {v:k for k, v in word2index.items()}\n",
    "\n",
    "tag2index = {}\n",
    "for tag in tagset:\n",
    "    if tag2index.get(tag) is None:\n",
    "        tag2index[tag] = len(tag2index)\n",
    "index2tag = {v:k for k, v in tag2index.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size = 2\n",
    "windows = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['<DUMMY>', '<DUMMY>', 'Sao', 'Paulo', '('], 'B-LOC']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy = ['<DUMMY>'] * window_size\n",
    "for sample in data:\n",
    "    window = list(nltk.ngrams(dummy + list(sample[0]) + dummy, window_size * 2 + 1))\n",
    "    windows.extend([[list(window[i]), sample[1][i]] for i in range(len(sample[0]))])\n",
    "windows[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "678377"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(windows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(windows)\n",
    "\n",
    "train_data = windows[:int(len(windows) * 0.9)]\n",
    "test_data = windows[int(len(windows) * 0.9):]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WindowClassifier(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_size, window_size, hidden_size, output_size):\n",
    "        super(WindowClassifier, self).__init__()\n",
    "        \n",
    "        self.embed = nn.Embedding(vocab_size, embedding_size)\n",
    "        self.h_layer1 = nn.Linear(embedding_size * (window_size * 2 + 1), hidden_size)\n",
    "        self.h_layer2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.o_layer = nn.Linear(hidden_size, output_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.softmax = nn.LogSoftmax(dim = 1)\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        \n",
    "    def forward(self, inputs, is_training = False):\n",
    "        embeds = self.embed(inputs) # B x W x D\n",
    "        concated = embeds.view(-1, embeds.size(1)*embeds.size(2)) # B x (W*D)\n",
    "        h0 = self.relu(self.h_layer1(concated))\n",
    "        if is_training:\n",
    "            h0 = self.dropout(h0)\n",
    "        h1 = self.relu(self.h_layer2(h0))\n",
    "        if is_training:\n",
    "            h1 = self.dropout(h1)\n",
    "        out = self.softmax(self.o_layer(h1))\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128\n",
    "EMBEDDING_SIZE = 50 # x (WINDOW_SIZE*2+1) = 250\n",
    "HIDDEN_SIZE = 300\n",
    "EPOCH = 3\n",
    "LEARNING_RATE = 0.001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = WindowClassifier(len(word2index), EMBEDDING_SIZE, window_size, HIDDEN_SIZE, len(tag2index))\n",
    "if use_cuda:\n",
    "    model = model.cuda()\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0/3] mean_loss : 2.08\n",
      "[0/3] mean_loss : 0.47\n",
      "[0/3] mean_loss : 0.38\n",
      "[0/3] mean_loss : 0.32\n",
      "[0/3] mean_loss : 0.29\n",
      "[1/3] mean_loss : 0.20\n",
      "[1/3] mean_loss : 0.22\n",
      "[1/3] mean_loss : 0.21\n",
      "[1/3] mean_loss : 0.20\n",
      "[1/3] mean_loss : 0.19\n",
      "[2/3] mean_loss : 0.18\n",
      "[2/3] mean_loss : 0.15\n",
      "[2/3] mean_loss : 0.14\n",
      "[2/3] mean_loss : 0.14\n",
      "[2/3] mean_loss : 0.14\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(EPOCH):\n",
    "    losses = []\n",
    "    for i, batch in enumerate(getBatch(BATCH_SIZE, train_data)):\n",
    "        x, y = list(zip(*batch))\n",
    "        inputs = torch.cat([prepare_sequence(sent, word2index).view(1, -1) for sent in x])\n",
    "        targets = torch.cat([prepare_tag(tag, tag2index) for tag in y])\n",
    "        model.zero_grad()\n",
    "        preds = model(inputs, is_training = True)\n",
    "        loss = loss_function(preds, targets)\n",
    "        losses.append(loss.data.tolist())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if i % 1000 == 0:\n",
    "            print(\"[%d/%d] mean_loss : %0.2f\" %(epoch, EPOCH, np.mean(losses)))\n",
    "            losses = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![train_result](image/word_window_classification_train_result.png)\n",
    "- train은 GPU가 장착되어 있는 컴퓨터에서 대신 시행했다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "for_f1_score = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = 0\n",
    "for test in test_data:\n",
    "    x, y = test[0], test[1]\n",
    "    input_ = prepare_sequence(x, word2index).view(1, -1)\n",
    "    \n",
    "    i = model(input_).max(1)[1]\n",
    "    pred = index2tag[i.data.tolist()]\n",
    "    for_f1_socre.append([pred, y])\n",
    "    if pred == y:\n",
    "        accuracy += 1\n",
    "        \n",
    "print(accuracy/len(test_data) * 100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
